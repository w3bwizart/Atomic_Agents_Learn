{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# A Deep dive into the Atomic Agents framework.\n",
    "This series aims to provide an in-depth understanding of each building block within the Atomic Agents framework, starting with the BaseAgent class. \n",
    "Whether you're a seasoned developer or new to AI agent development, this series will offer valuable insights into how to effectively utilize and extend the Atomic Agents framework for your AI applications.\n",
    "\n",
    "# What is the Atomic Agents Framework?\n",
    "The Atomic Agents framework is a new approach to AI development, inspired by the principles of Atomic Design. This framework breaks down AI systems into smaller, self-contained, and reusable components, much like LEGO blocks. This modularity ensures that AI development is both flexible and predictable, allowing developers to create complex AI applications with ease and confidence.\n",
    "\n",
    "# Why a BaseAgent?\n",
    "The BaseAgent class serves as the foundational building block for creating AI agents within the Atomic Agents framework. It encapsulates essential functionalities such as handling user inputs, generating responses, and managing chat history. By dissecting this class, we aim to uncover the \"magic\" behind its operations and provide a clear roadmap for setting up and customizing your own AI agents\n",
    "\n",
    "If you just want to get started checkout the quickstart notebook: https://github.com/KennyVaneetvelde/atomic_agents/blob/main/examples/notebooks/quickstart.ipynb\n",
    "\n",
    "# BaseAgent\n",
    "Let's have a look at what the `BaseAgent` provides.\n",
    "This class provides the core functionality for handling chat interactions, including managing memory, generating system prompts, and obtaining responses from a language model.\n",
    "\n",
    "#### Attributes\n",
    "- **input_schema** (Type[BaseAgentIO]): Schema for the structure of the input data.\n",
    "- **output_schema** (Type[BaseAgentIO]): Schema for the structure of the output data.\n",
    "- **client**: Client for interacting with the language model.\n",
    "- **model** (str): The model to use for generating responses.\n",
    "- **memory** (**AgentMemory**): Memory component for storing chat history of the agent.\n",
    "- **system_prompt_generator** (**SystemPromptGenerator**): Component for generating system prompts.\n",
    "- **initial_memory** (**AgentMemory**): Initial state of the memory.\n",
    "\n",
    "#### Public Functions\n",
    "- **reset_memory()**: Resets the memory to its initial state.\n",
    "- **get_response()**:  Obtains a response from the language model.\n",
    "- **run()**:  Runs the chat agent with the given user input.\n",
    "- **get_context_provider()**:  Retrieves a context provider by name.\n",
    "- **register_context_provider()**: Registers a new context provider.\n",
    "- **unregister_context_provider()**:  Unregister an existing context provider.\n",
    "\n",
    "#### Private Functions:\n",
    "- **get_and_handle_response()**: Handles obtaining and processing the response.\n",
    "- **init_run()**: Initializes the run with the given user input. \n",
    "- **pre_run()**: Prepares for the run. This method can be overridden by subclasses to add custom pre-run logic.\n",
    "- **post_run()**: Finalizes the run with the given response.\n",
    "\n",
    "Here is an overview of what we have to define to be able to create an agent.\n",
    "To create the `BaseAgent` we need to prepare all the parts we need to configure and instantiate the Agent.\n",
    "\n",
    "![BaseAgent overview schema](../assets/baseAgent.png 'BaseAgent overview schema')\n",
    "\n",
    "So let's get starting, first we need to install the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary packages\n",
    "%pip install atomic-agents openai instructor Groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will do the nessesary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to be able to load an API_key from a .env file \n",
    "from dotenv import load_dotenv\n",
    "# we need the os to get to out environment variables\n",
    "import os\n",
    "# we need to be able to provide a date\n",
    "import datetime\n",
    "# we need instructor to interact with the model\n",
    "import instructor\n",
    "# we need groq because it's free and easy to setup\n",
    "from groq import Groq\n",
    "\n",
    "# we need the AgentMemory because this is the memory of the agent\n",
    "from atomic_agents.lib.components.agent_memory import AgentMemory\n",
    "# we need the BaseAgent because it's the core of the framework \n",
    "# we need the BaseAgentConfig to create the configuration for the BaseAgent\n",
    "from atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig\n",
    "# we need the SystemPromptInfo to create our system prompt\n",
    "# we need the SystemPromptGenerator to generate the system prompt based on the SystemPromptInfo\n",
    "# we need the SystemPromptContextProviderBase to create a context provider by extending that class\n",
    "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptInfo, SystemPromptContextProviderBase\n",
    "\n",
    "# we need the console to be able to print and have a peek into the magic\n",
    "from rich.console import Console\n",
    "# we need Markdown to convert the system prompt into a nice format to read in the console\n",
    "from rich.markdown import Markdown\n",
    "# we need the console for obvious reasons\n",
    "console = Console()\n",
    "# we need to load the environment variables from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets start with defining a system prompt, to create a system prompt you will need the `SystemPromptInfo`. \n",
    "\n",
    "# SystemPromptInfo\n",
    "In the `SystemPromptInfo` we will define everything we need to create a system prompt.\n",
    "\n",
    "## Arguments\n",
    "- **background**: this is the initial description of the agent and what its purpose is. \n",
    "This is the place to define the role the agent should behave on. \n",
    "Keep in mind its not really a rol its more telling the Agent to narrow the topics it should use to search for in its corpus.\n",
    "\n",
    "- **steps**: these are the internal assistant steps you want the agent to take.\n",
    "\n",
    "- **output_instructions**: this is where you define how the agent should answer the user.\n",
    "\n",
    "- **context_providers**: this can be any provider you want to add to the system prompt. \n",
    "It can be a date, some lorumIpsum, the model you are using, whatever extra context you want to provide to the system prompt and the agent needs to know of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SystemPromptInfo object\n",
    "system_prompt_info = SystemPromptInfo(    \n",
    "    background=[\n",
    "        'This assistant is a general-purpose AI designed to be helpful and friendly.',\n",
    "    ],\n",
    "    steps=[\n",
    "        'Understand the user input.',\n",
    "        'Reason about the input.',\n",
    "        'Respond to the user.',\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        'Provide helpful and relevant information to assist the user.',\n",
    "        'Be friendly and respectful in all conversations.',\n",
    "        'Always use the available additional information and context to enhance the response',\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets have a look and see what's defined in the `SystemPromptInfo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemPromptInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">background</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'This assistant is a general-purpose AI designed to be helpful and friendly.'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Understand the user input.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Reason about the input.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Respond to the user.'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">output_instructions</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Provide helpful and relevant information to assist the user.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Be friendly and respectful in all conversations.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Always use the available additional information and context to enhance the response'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">context_providers</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSystemPromptInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mbackground\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'This assistant is a general-purpose AI designed to be helpful and friendly.'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Understand the user input.'\u001b[0m, \u001b[32m'Reason about the input.'\u001b[0m, \u001b[32m'Respond to the user.'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33moutput_instructions\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'Provide helpful and relevant information to assist the user.'\u001b[0m,\n",
       "        \u001b[32m'Be friendly and respectful in all conversations.'\u001b[0m,\n",
       "        \u001b[32m'Always use the available additional information and context to enhance the response'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcontext_providers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log the SystemPromptInfo \n",
    "console.print(system_prompt_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Providers\n",
    "As mentiond a context provider can be anything you want to be added to the system prompt. \n",
    "So lets add a data so the agent knows what day it is when we have a conversation.\n",
    "To create a context provider we need to use the `SystemPromptContextProviderBase` class and extend it.\n",
    "We will create a context provider to provide a Date to each system prompt and provide a format attribute so you can change the date format the way you want.\n",
    "\n",
    "## Attributes\n",
    "- **Title**: the title for your context provider, this can be whatever you want it to be named.\n",
    "\n",
    "## Functions\n",
    "- **get_info()**: is a function you can overwrite to return whatever you define you want to get from your context provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extend the SystemPromptContextProviderBase\n",
    "class CurrentDateContextProvider(SystemPromptContextProviderBase):\n",
    "    def __init__(self, format: str = '%Y-%m-%d %H:%M:%S', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.format = format\n",
    "\n",
    "    def get_info(self) -> str:\n",
    "        return f'Date: {datetime.datetime.now().strftime(self.format)}' # **Remember** 'title' is from the base class we are extending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the new CurrentDateContextProvider, \n",
    "# # keep in mind that now we do have to pass the title attribute from the base class because its required.\n",
    "provider = CurrentDateContextProvider(title='Datetime')\n",
    "\n",
    "# Call the get_info() method on the instance and print the result.\n",
    "console.print(provider.get_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined a new `CurrentDateContextProvider` we can add it to the `SystemPromptInfo` context_providers attribute. \n",
    "\n",
    "Do know that you could also register and unregister a context provider straight on the BaseChatAgent. We will see this later, but for now we pass it to the `SystemPromptInfo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new CurrentDateContextProvider to the SystemPromptInfo\n",
    "system_prompt_info.context_providers = {\n",
    "    'date': CurrentDateContextProvider(\n",
    "        title='Datetime Context Provider', \n",
    "        format='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "}\n",
    "console.print(system_prompt_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SystemPromptGenerator\n",
    "Now we are ready to generate a system prompt, to do so we need the `SystemPromptInfo` and the `SystemPromptGenerator`.\n",
    "\n",
    "Remember we imported the `Markdown`, so we are using it to give our console logs a nice format, it's not needed to work with agents because the framework does it by default for the system prompt. \n",
    "We do it for the readability in our console.\n",
    "\n",
    "## Arguments\n",
    "- **system_prompt_info**: which holds background, steps, output_instructions and context_providers\n",
    "\n",
    "## Functions\n",
    "- **generate_prompt()**: will generate a system prompt from the `SystemPromptInfo` to be used by the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the SystemPromptGenerator with the SystemPromptInfo object\n",
    "system_prompt_generator = SystemPromptGenerator(system_prompt_info)\n",
    "# log the system prompt\n",
    "console.print(Markdown(system_prompt_generator.generate_prompt()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "1. We created a `SystemPromptInfo` config object, \n",
    "2. We created the `CurrentDateContextProvider` context provider.\n",
    "3. We added the `CurrentDateContextProvider` to the `SystemPromptInfo`.\n",
    "4. We defined a `SystemPromptGenerator` that used the `SystemPromptInfo`.\n",
    "\n",
    "The next step is adding some memory to the agent to keep track of it's conversation.\n",
    "\n",
    "# AgentMemory\n",
    "The `AgentMemory` is used by the agent to keep track of the conversation. Later when you want to use multiple agent you could even share this memory with other agents for example. \n",
    "To add to a `AgentMemory` we make use of a `Message` with a predefined format.\n",
    "\n",
    "## Attributes:\n",
    "- **History**:  A list of messages representing the chat history.\n",
    "\n",
    "## Functions\n",
    "- **add_message()**: A message has several arguments:\n",
    "    - **role** (str): The role of the message sender, user or agent.\n",
    "    - **content** (str): The content of the message.\n",
    "    - **tool_message** (Optional[Dict]): Optional tool message to be included when making use of a tool\n",
    "    - **tool_id** (Optional[str]): Optional unique identifier for the tool call when making use of a tool\n",
    "\n",
    "- **get_history()**:Retrieves the chat history.\n",
    "\n",
    "- **dump()**: Converts the chat history to a list of dictionaries.\n",
    "\n",
    "- **load()**:  Loads the chat history from a list of dictionaries.\n",
    "\n",
    "- **copy()**:  Creates a copy of the chat memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define initial memory with a greeting message from the assistant\n",
    "initial_memory_message = [\n",
    "    {'role': 'assistant', \n",
    "     'content': 'How do you do and what can I do for you today?',\n",
    "     'tool_message': 'no tool used',\n",
    "     'tool_id': None\n",
    "    } \n",
    "]\n",
    "# Initialize the agent memory to store conversation history\n",
    "agent_memory = AgentMemory()\n",
    "\n",
    "# Load the initial memory into the agent memory\n",
    "agent_memory.load(initial_memory_message)\n",
    "\n",
    "# examples\n",
    "console.print(agent_memory.dump())\n",
    "console.print(agent_memory.get_history())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same as before we need to start with a config object which in this case is the `BaseAgentConfig` so let's start defining everything we need for the `BaseAgentConfig`.\n",
    "\n",
    "First we need a Client but to configure this client we first need to add our API_key and as mentioned at the start we will use Groq. \n",
    "If you don't have an account yet now is the time to create one and get your API_Key. \n",
    "You could also use OpenAI or Anthropic whatever you want, you can use the Instructor library for this. \n",
    "You could even use a local Ollama server and use that if you have a beefy PC to run your models on. \n",
    "\n",
    "Let's start with the API_Key.\n",
    "For safety and good organization use a .env file to store your keys and make sure to add it to your .gitignore file before commiting your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your API_Key from your enviroment variable if it's not there add your API_Key here \n",
    "# Keep in mind to not make this code public with your key\n",
    "API_KEY = ''\n",
    "if not API_KEY:\n",
    "    # get the environments variable\n",
    "    API_KEY = os.getenv('GROQ_API_KEY') # OPENAI_API_KEY, OLLAMA_API_KEY, ...\n",
    "    \n",
    "if not API_KEY:\n",
    "    raise ValueError('API key is not set. Please set the API key as a static variable or in an environment variable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the client using the `instructor` library for Groq.\n",
    "\n",
    "For more details visit Instructor at: https://github.com/jxnl/instructor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_groq(\n",
    "    Groq(api_key=API_KEY,),\n",
    "    mode=instructor.Mode.TOOLS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input_schema / Output_schema\n",
    "Lets discuss the input/output schema's and why they are different then the input/output_instructions. \n",
    "First of all the instructions are part of the `SystemPrompt` and will be provide via the `SystemPromptInfo`.\n",
    "\n",
    "- `output_instruction` = this is the place where you want to define the agent and how it should behave. You can mention what type of agent it is or which role you want it to act on. this is where you want to tell how the agent to response, be polite, be helpful, guide me step by step or ask a new question after every answer you provide.\n",
    "\n",
    "\n",
    "The schema's are part of the agent itself and will be provided via the `BaseAgentConfig`.\n",
    "The schema's are about the data structure, for example if you want to receive an answer in a formated structure or provide input based on the answer of 2 other agents this is the place.\n",
    "- `input_schema` = you need the response of 2 other agents to feed this agent then you would define this in the input_schema\n",
    "- `output_schema` = you want a formated output like a blog article which will always nee to have a Title, Summary, Numbers, Story, Sources, Keywords, Hashtags then you would define this in the output_schema. You could also define things like you want at least 3000 words as a response or exactly 5 results.\n",
    "\n",
    "So now that we know the difference we can determin that in this case we don't need the the schema's but only the instruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an AI Agent\n",
    "\n",
    "So we came to the final part of this notebook, the part you were waiting for to create an Agent after a deep dive in the `BaseAgent` Class and everything that is needed.\n",
    "Now that we have created all the seperate blocks, we can now configure the Agent and We will create the main loop of the application. \n",
    "\n",
    "We will also add some code to be able to exit the conversation when typing `/exit` or `/quit`. \n",
    "Use this if you want to go to the last part of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# configure the agent\n",
    "agent = BaseAgent(\n",
    "    config=BaseAgentConfig(\n",
    "        client=client,\n",
    "        system_prompt_generator=system_prompt_generator,\n",
    "        model='llama3-70b-8192', # Specify the model you want to use\n",
    "        memory=agent_memory\n",
    "    )\n",
    ")\n",
    "\n",
    "# Main loop for testing the chat agent\n",
    "# take the 1st message from the agentMemory and prefix with the role: Agent\n",
    "console.print(f'Agent: {initial_memory_message[0][\"content\"]}')\n",
    "\n",
    "while True:\n",
    "    # get the user inpput and prefix with the role: User\n",
    "    user_input = input('User: ')\n",
    "    print(f'User: {user_input}')\n",
    "    \n",
    "    if user_input.lower() in ['/exit', '/quit']:\n",
    "        print('Exiting chat, see you later ...')\n",
    "        break\n",
    "    \n",
    "    # run the agent and asign the user input to the conversation\n",
    "    response = agent.run(agent.input_schema(chat_message=user_input))\n",
    "    print(f'Agent: {response.chat_message}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start a conversation with Llama3 via Groq.\n",
    "To test the context provider ask the agent for the date: 'What day is it today?'\n",
    "You will notice that the agent is aware of the date. \n",
    "\n",
    "`Agent: Today's date is 2024-07-07`\n",
    "\n",
    "Without the context provider it will tell you it's not aware of time.\n",
    "\n",
    "`Agent: I'm happy to help! However, I'm a large language model, I don't have have access to real-time information, including the current date.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets play \n",
    "# get the context provider\n",
    "console.print('# get the context provider #')\n",
    "console.print(agent.get_context_provider(provider_name=\"date\"))\n",
    "\n",
    "# get the system prompt\n",
    "console.print('# get the system prompt with context provider#')\n",
    "console.print(f'system prompt = {agent.system_prompt_generator.generate_prompt()}')\n",
    "\n",
    "# unregister the context provider\n",
    "console.print('# Unregister the context provider #')\n",
    "agent.unregister_context_provider('date')\n",
    "\n",
    "# get the system prompt\n",
    "console.print('# get the system prompt now without context provider #')\n",
    "console.print(f'system prompt = {agent.system_prompt_generator.generate_prompt()}')\n",
    "\n",
    "# register the context provider\n",
    "console.print('# register the context provider #')\n",
    "agent.register_context_provider('date', CurrentDateContextProvider(\n",
    "        title='Datetime Context Provider', \n",
    "        format='%Y-%m-%d %H:%M:%S')\n",
    ")\n",
    "\n",
    "# get the system prompt\n",
    "console.print('# get the system prompt again with context provider #')\n",
    "console.print(agent.system_prompt_generator.generate_prompt())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Congratulations on completing this deep dive into the BaseChatAgent class! \n",
    "By now, you should have a solid understanding of its internal workings, setup requirements, and how to effectively utilize and extend it for your AI applications. This foundational knowledge will serve as a crucial stepping stone as we continue to explore the Atomic Agents framework.\n",
    "\n",
    "# What's Next?\n",
    "In the next notebook of this series, we will shift our focus to another essential component of the Atomic Agents framework: Tools. We will explore how to create and use these tools to enhance the capabilities of your AI agents. Specifically, we will cover:\n",
    "\n",
    "- The purpose and functionality of Tools within the framework.\n",
    "- Step-by-step instructions on how to create custom Tools.\n",
    "- Practical examples demonstrating how to integrate and utilize Tools in your AI projects.\n",
    "\n",
    "Stay tuned for an exciting journey into the world of Tools, where we will unlock even more potential for your AI agents. Thank you for following along, and we look forward to seeing you in the next notebook!\n",
    "\n",
    "\n",
    "For a complete script check it out at:  \n",
    "/scripts/A_deep_dive_into_atomic_agents-BaseAgent.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
